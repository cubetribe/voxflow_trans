# ğŸš€ Backend - Voxtral Server Architecture

## Architecture Overview

### Services
1. **Node.js API Gateway** (Port 3000)
   - Request Routing
   - Authentication
   - WebSocket Management
   - File Handling

2. **Python Voxtral Service** (Port 8000)
   - Model Loading
   - Audio Processing
   - Transcription Engine
   - Streaming Support

## Tech Stack

### Node.js Service
- **Express.js** mit TypeScript
- **Socket.io** fÃ¼r Real-time
- **Multer** fÃ¼r File Uploads
- **Bull** fÃ¼r Job Queue
- **Redis** fÃ¼r Caching
- **SQLite** fÃ¼r Metadata

### Python Service
- **FastAPI** fÃ¼r REST API
- **vLLM** oder **Hugging Face Transformers**
- **MLX** fÃ¼r Apple Silicon Optimization
- **Pydantic** fÃ¼r Data Validation
- **asyncio** fÃ¼r Async Processing
- **FFmpeg** Integration

## Project Structure

```
backend/
â”œâ”€â”€ node-service/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ controllers/
â”‚   â”‚   â”‚   â”œâ”€â”€ audio.controller.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ transcription.controller.ts
â”‚   â”‚   â”‚   â””â”€â”€ health.controller.ts
â”‚   â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.middleware.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ error.middleware.ts
â”‚   â”‚   â”‚   â””â”€â”€ validation.middleware.ts
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ audio.service.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ queue.service.ts
â”‚   â”‚   â”‚   â””â”€â”€ storage.service.ts
â”‚   â”‚   â”œâ”€â”€ sockets/
â”‚   â”‚   â”‚   â”œâ”€â”€ transcription.socket.ts
â”‚   â”‚   â”‚   â””â”€â”€ connection.manager.ts
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ app.ts
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ tsconfig.json
â”‚
â””â”€â”€ python-service/
    â”œâ”€â”€ app/
    â”‚   â”œâ”€â”€ api/
    â”‚   â”‚   â”œâ”€â”€ endpoints/
    â”‚   â”‚   â”‚   â”œâ”€â”€ transcribe.py
    â”‚   â”‚   â”‚   â”œâ”€â”€ health.py
    â”‚   â”‚   â”‚   â””â”€â”€ models.py
    â”‚   â”‚   â””â”€â”€ dependencies.py
    â”‚   â”œâ”€â”€ core/
    â”‚   â”‚   â”œâ”€â”€ config.py
    â”‚   â”‚   â”œâ”€â”€ voxtral_engine.py
    â”‚   â”‚   â””â”€â”€ audio_processor.py
    â”‚   â”œâ”€â”€ models/
    â”‚   â”‚   â”œâ”€â”€ transcription.py
    â”‚   â”‚   â””â”€â”€ audio.py
    â”‚   â”œâ”€â”€ services/
    â”‚   â”‚   â”œâ”€â”€ voxtral_service.py
    â”‚   â”‚   â”œâ”€â”€ streaming_service.py
    â”‚   â”‚   â””â”€â”€ preprocessing.py
    â”‚   â””â”€â”€ main.py
    â”œâ”€â”€ requirements.txt
    â””â”€â”€ Dockerfile
```

## Voxtral Integration

### Model Setup
```python
# Voxtral Configuration fÃ¼r M4 Max
class VoxtralConfig:
    model_name = "mistralai/Voxtral-Mini-3B-2507"  # oder Small-24B
    device = "mps"  # Metal Performance Shaders fÃ¼r Apple Silicon
    precision = "float16"
    max_audio_length = 30 * 60  # 30 Minuten
    chunk_size = 30  # Sekunden
    overlap = 2  # Sekunden Ãœberlappung
```

### Audio Processing Pipeline
1. **Input Validation**
   - Format Detection
   - Duration Check
   - Quality Assessment

2. **Preprocessing**
   - Resampling zu 16kHz
   - Mono Conversion
   - Noise Reduction (optional)
   - VAD (Voice Activity Detection)

3. **Chunking Strategy**
   - Smart Splitting bei Silence
   - Overlap fÃ¼r Context
   - Batch Processing

4. **Transcription**
   - Streaming Mode fÃ¼r Live Audio
   - Batch Mode fÃ¼r Files
   - Language Detection
   - Confidence Scores

## API Endpoints

### Node.js Gateway

```typescript
// REST Endpoints
POST   /api/transcribe/upload     // File Upload
POST   /api/transcribe/start      // Start Live Recording
GET    /api/transcriptions        // List Transcriptions
GET    /api/transcription/:id     // Get Single Transcription
DELETE /api/transcription/:id     // Delete Transcription
GET    /api/export/:id/:format    // Export (TXT, SRT, JSON)

// WebSocket Events
ws: /socket
  -> audio:chunk              // Client sends audio chunk
  <- transcription:partial    // Server sends partial result
  <- transcription:final      // Server sends final result
  <- error                    // Error notification
```

### Python FastAPI

```python
# Core Endpoints
POST   /transcribe/file       # Process uploaded file
POST   /transcribe/stream     # Handle streaming audio
GET    /models/status         # Model loading status
GET    /health               # Service health check
POST   /config/update        # Update model config
```

## Data Flow

```
Client Audio â†’ Node.js Gateway â†’ Queue â†’ Python Service â†’ Voxtral Model
                     â†“                           â†“
                  Storage                   Transcription
                     â†“                           â†“
                  Database â† â† â† â† â† â† â† Results
```

## Performance Optimizations

### 1. Model Loading
- **Lazy Loading** bei ersten Request
- **Model Caching** im Memory
- **Warm-up Routine** fÃ¼r schnellere erste Inference

### 2. Batching
- Sammle mehrere kurze Requests
- Batch Processing fÃ¼r Effizienz
- Priority Queue fÃ¼r Live Streams

### 3. Caching Strategy
- Redis fÃ¼r hÃ¤ufige Anfragen
- LRU Cache fÃ¼r Transcriptions
- Audio Fingerprinting fÃ¼r Duplikate

### 4. Resource Management
- Connection Pooling
- Memory Limits
- GPU Memory Management
- Graceful Degradation

## Apple Silicon Optimizations

### MLX Integration
```python
# Nutze Apple's ML Framework
import mlx
import mlx.nn as nn
from mlx.utils import tree_map

# Optimierungen fÃ¼r M4 Max
- Unified Memory Architecture
- Neural Engine Utilization
- Metal Performance Shaders
```

### Memory Management
- Efficient Buffer Allocation
- Zero-Copy Operations
- Streaming Processing

## Error Handling

### Retry Logic
- Exponential Backoff
- Circuit Breaker Pattern
- Fallback Mechanisms

### Error Types
1. **Audio Errors**: Invalid format, corrupted file
2. **Model Errors**: OOM, inference failure
3. **Network Errors**: Timeout, connection lost
4. **System Errors**: Disk full, permission denied

## Monitoring & Logging

### Metrics
- Request/Response Times
- Queue Length
- Model Inference Time
- Memory Usage
- Error Rates

### Logging
- Structured Logging (JSON)
- Log Levels
- Request Tracing
- Performance Profiling

## Security

### Authentication
- API Key fÃ¼r REST
- JWT fÃ¼r WebSocket
- Rate Limiting
- IP Whitelisting (optional)

### Data Protection
- Audio Encryption at Rest
- Secure File Upload
- Input Validation
- SQL Injection Prevention

## Deployment

### Development
```bash
# Node.js Service
cd node-service
npm install
npm run dev

# Python Service
cd python-service
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
uvicorn app.main:app --reload
```

### Production
- PM2 fÃ¼r Node.js
- Gunicorn fÃ¼r Python
- Nginx als Reverse Proxy
- Systemd Services
- Health Checks
- Auto-restart

## Scaling Considerations

### Horizontal Scaling
- Load Balancer
- Multiple Python Workers
- Redis Cluster
- Shared Storage

### Vertical Scaling
- GPU Scheduling
- Memory Allocation
- CPU Affinity
- Process Priority